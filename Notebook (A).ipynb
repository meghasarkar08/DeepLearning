{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-10T17:18:32.210481Z","iopub.execute_input":"2022-02-10T17:18:32.211214Z","iopub.status.idle":"2022-02-10T17:18:32.218872Z","shell.execute_reply.started":"2022-02-10T17:18:32.211175Z","shell.execute_reply":"2022-02-10T17:18:32.218101Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"Import modules like pandas and numpy","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.221162Z","iopub.execute_input":"2022-02-10T17:18:32.221599Z","iopub.status.idle":"2022-02-10T17:18:32.233443Z","shell.execute_reply.started":"2022-02-10T17:18:32.221551Z","shell.execute_reply":"2022-02-10T17:18:32.232896Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"Read dataset into pandas dataframe","metadata":{}},{"cell_type":"code","source":"concrete_data = pd.read_csv('../input/coursera-test/concrete_data.csv')\nconcrete_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.234498Z","iopub.execute_input":"2022-02-10T17:18:32.234876Z","iopub.status.idle":"2022-02-10T17:18:32.262711Z","shell.execute_reply.started":"2022-02-10T17:18:32.234839Z","shell.execute_reply":"2022-02-10T17:18:32.262060Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"#Check for missing values\nconcrete_data.describe\nconcrete_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.263956Z","iopub.execute_input":"2022-02-10T17:18:32.264164Z","iopub.status.idle":"2022-02-10T17:18:32.271946Z","shell.execute_reply.started":"2022-02-10T17:18:32.264136Z","shell.execute_reply":"2022-02-10T17:18:32.271078Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"#Split data into predators and target\nconcrete_data_columns = concrete_data.columns\npredictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\ntarget = concrete_data['Strength'] # Strength column","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.273972Z","iopub.execute_input":"2022-02-10T17:18:32.274377Z","iopub.status.idle":"2022-02-10T17:18:32.284273Z","shell.execute_reply.started":"2022-02-10T17:18:32.274344Z","shell.execute_reply":"2022-02-10T17:18:32.283434Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"predictors.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.285164Z","iopub.execute_input":"2022-02-10T17:18:32.285909Z","iopub.status.idle":"2022-02-10T17:18:32.303634Z","shell.execute_reply.started":"2022-02-10T17:18:32.285879Z","shell.execute_reply":"2022-02-10T17:18:32.302888Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"target.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.304991Z","iopub.execute_input":"2022-02-10T17:18:32.305515Z","iopub.status.idle":"2022-02-10T17:18:32.315997Z","shell.execute_reply.started":"2022-02-10T17:18:32.305480Z","shell.execute_reply":"2022-02-10T17:18:32.315384Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"#Number of Predictors\nn_cols = predictors.shape[1] # number of predictors\nn_cols","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.316825Z","iopub.execute_input":"2022-02-10T17:18:32.317430Z","iopub.status.idle":"2022-02-10T17:18:32.326151Z","shell.execute_reply.started":"2022-02-10T17:18:32.317403Z","shell.execute_reply":"2022-02-10T17:18:32.325344Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"#Import Keras module\nimport keras","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.327259Z","iopub.execute_input":"2022-02-10T17:18:32.327506Z","iopub.status.idle":"2022-02-10T17:18:32.336227Z","shell.execute_reply.started":"2022-02-10T17:18:32.327459Z","shell.execute_reply":"2022-02-10T17:18:32.335650Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.337257Z","iopub.execute_input":"2022-02-10T17:18:32.337708Z","iopub.status.idle":"2022-02-10T17:18:32.346179Z","shell.execute_reply.started":"2022-02-10T17:18:32.337655Z","shell.execute_reply":"2022-02-10T17:18:32.345677Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# define regression model\ndef regression_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n    model.add(Dense(1))\n    \n    # compile model\n    model.compile(optimizer='adam', loss='mean_squared_error')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.398337Z","iopub.execute_input":"2022-02-10T17:18:32.398734Z","iopub.status.idle":"2022-02-10T17:18:32.403580Z","shell.execute_reply.started":"2022-02-10T17:18:32.398683Z","shell.execute_reply":"2022-02-10T17:18:32.403109Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"#Need to import scikit-learn in order to randomly split the data into a training and test sets\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.404907Z","iopub.execute_input":"2022-02-10T17:18:32.405088Z","iopub.status.idle":"2022-02-10T17:18:32.417570Z","shell.execute_reply.started":"2022-02-10T17:18:32.405064Z","shell.execute_reply":"2022-02-10T17:18:32.416959Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"#Split data into training and testing set, where 30% assigned to testing\nX_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.418449Z","iopub.execute_input":"2022-02-10T17:18:32.418686Z","iopub.status.idle":"2022-02-10T17:18:32.432890Z","shell.execute_reply.started":"2022-02-10T17:18:32.418662Z","shell.execute_reply":"2022-02-10T17:18:32.432288Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# build the model\nmodel = regression_model()","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.433744Z","iopub.execute_input":"2022-02-10T17:18:32.434068Z","iopub.status.idle":"2022-02-10T17:18:32.460167Z","shell.execute_reply.started":"2022-02-10T17:18:32.434044Z","shell.execute_reply":"2022-02-10T17:18:32.459509Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"# fit the model\nepochs = 50\nmodel.fit(X_train, y_train, epochs=epochs, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:32.461586Z","iopub.execute_input":"2022-02-10T17:18:32.461769Z","iopub.status.idle":"2022-02-10T17:18:34.108571Z","shell.execute_reply.started":"2022-02-10T17:18:32.461746Z","shell.execute_reply":"2022-02-10T17:18:34.107740Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"#Need to evaluate the model on the test data.\n\nloss_val = model.evaluate(X_test, y_test)\ny_pred = model.predict(X_test)\nloss_val","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:34.109859Z","iopub.execute_input":"2022-02-10T17:18:34.110687Z","iopub.status.idle":"2022-02-10T17:18:34.382068Z","shell.execute_reply.started":"2022-02-10T17:18:34.110646Z","shell.execute_reply":"2022-02-10T17:18:34.381323Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"#Import mean squared function\nfrom sklearn.metrics import mean_squared_error","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:34.383029Z","iopub.execute_input":"2022-02-10T17:18:34.383200Z","iopub.status.idle":"2022-02-10T17:18:34.386362Z","shell.execute_reply.started":"2022-02-10T17:18:34.383176Z","shell.execute_reply":"2022-02-10T17:18:34.385949Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"mean_square_error = mean_squared_error(y_test, y_pred)\nmean = np.mean(mean_square_error)\nstandard_deviation = np.std(mean_square_error)\nprint(mean, standard_deviation)","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:34.387088Z","iopub.execute_input":"2022-02-10T17:18:34.387673Z","iopub.status.idle":"2022-02-10T17:18:34.398857Z","shell.execute_reply.started":"2022-02-10T17:18:34.387648Z","shell.execute_reply":"2022-02-10T17:18:34.398273Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"#Create a list of 50 mean squared errors and report mean and the standard deviation of the mean squared errors.\n\ntotal_mean_squared_errors = 50\nepochs = 50\nmean_squared_errors = []\nfor i in range(0, total_mean_squared_errors):\n    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=i)\n    model.fit(X_train, y_train, epochs=epochs, verbose=0)\n    MSE = model.evaluate(X_test, y_test, verbose=0)\n    print(\"Mean Square error # \"+str(i+1)+\": \"+str(MSE))\n    y_pred = model.predict(X_test)\n    mean_square_error = mean_squared_error(y_test, y_pred)\n    mean_squared_errors.append(mean_square_error)\n\nmean_squared_errors = np.array(mean_squared_errors)\nmean = np.mean(mean_squared_errors)\nstandard_deviation = np.std(mean_squared_errors)\nprint(\"Below is the mean and standard deviation of \" +str(total_mean_squared_errors) + \" mean squared errors without normalized data. Total number of epochs for each training is: \" +str(epochs) + \"\\n\")\nprint('\\n')\nprint(\"Mean: \"+str(mean))\nprint('\\n')\nprint(\"Standard Deviation: \"+str(standard_deviation))","metadata":{"execution":{"iopub.status.busy":"2022-02-10T17:18:34.399746Z","iopub.execute_input":"2022-02-10T17:18:34.400296Z","iopub.status.idle":"2022-02-10T17:19:29.476145Z","shell.execute_reply.started":"2022-02-10T17:18:34.400265Z","shell.execute_reply":"2022-02-10T17:19:29.475208Z"},"trusted":true},"execution_count":81,"outputs":[]}]}